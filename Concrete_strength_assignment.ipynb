{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1 : Load all the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import models,layers,optimizers,utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2 : Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "0   540.0    0.0     0.0  162.0               2.5           1040.0   \n",
       "1   540.0    0.0     0.0  162.0               2.5           1055.0   \n",
       "2   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "3   332.5  142.5     0.0  228.0               0.0            932.0   \n",
       "4   198.6  132.4     0.0  192.0               0.0            978.4   \n",
       "\n",
       "   fineaggregate  age  csMPa  \n",
       "0          676.0   28  79.99  \n",
       "1          676.0   28  61.89  \n",
       "2          594.0  270  40.27  \n",
       "3          594.0  365  41.05  \n",
       "4          825.5  360  44.30  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe=pd.read_csv(\"Concrete_Data_Yeh.csv\")\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cement</th>\n",
       "      <th>slag</th>\n",
       "      <th>flyash</th>\n",
       "      <th>water</th>\n",
       "      <th>superplasticizer</th>\n",
       "      <th>coarseaggregate</th>\n",
       "      <th>fineaggregate</th>\n",
       "      <th>age</th>\n",
       "      <th>csMPa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>425.0</td>\n",
       "      <td>106.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>151.4</td>\n",
       "      <td>18.6</td>\n",
       "      <td>936.0</td>\n",
       "      <td>803.7</td>\n",
       "      <td>28</td>\n",
       "      <td>61.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>212.0</td>\n",
       "      <td>141.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>203.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>973.4</td>\n",
       "      <td>750.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>331.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>825.0</td>\n",
       "      <td>28</td>\n",
       "      <td>31.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>968.0</td>\n",
       "      <td>885.0</td>\n",
       "      <td>7</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>355.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>12.3</td>\n",
       "      <td>967.0</td>\n",
       "      <td>871.0</td>\n",
       "      <td>28</td>\n",
       "      <td>55.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cement   slag  flyash  water  superplasticizer  coarseaggregate  \\\n",
       "119   425.0  106.3     0.0  151.4              18.6            936.0   \n",
       "691   212.0  141.3     0.0  203.5               0.0            973.4   \n",
       "786   331.0    0.0     0.0  192.0               0.0            978.0   \n",
       "626   236.0    0.0     0.0  193.0               0.0            968.0   \n",
       "498   355.0   19.0    97.0  145.0              12.3            967.0   \n",
       "\n",
       "     fineaggregate  age  csMPa  \n",
       "119          803.7   28  61.80  \n",
       "691          750.0    3   6.81  \n",
       "786          825.0   28  31.45  \n",
       "626          885.0    7   9.99  \n",
       "498          871.0   28  55.45  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Concrete= dataframe.sample(frac=1)\n",
    "Concrete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "concrete=Concrete.values\n",
    "x_train = concrete[:824,:8].astype('float')\n",
    "train_labels = concrete[:824,8]\n",
    "y_test = concrete[824:,:8].astype('float')\n",
    "test_labels = concrete[824:,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(824, 8)\n",
      "(824,)\n",
      "(206, 8)\n",
      "(206,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(train_labels.shape)\n",
    "print(y_test.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean=x_train.mean(axis=0)\n",
    "x_train-=mean\n",
    "std=x_train.std(axis=0)\n",
    "x_train/=std\n",
    "y_test-=mean\n",
    "y_test/=std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3:Slicing for Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val=x_train[:103] #totl 100% hain jisme se validation me 10% ja rahe hain\n",
    "partial_x_train=x_train[103:] #or baki partial me ja rahe ha\n",
    "val_label=train_labels[:103]\n",
    "partial_train_label=train_labels[103:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4:Building Model Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=models.Sequential()\n",
    "model.add(layers.Dense(64,activation='relu',input_shape=(partial_x_train.shape[1],)))\n",
    "model.add(layers.Dense(64,activation='relu'))\n",
    "model.add(layers.Dense(1)) #regression problem me last me koi bh func nai lagate\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse',\n",
    "              metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 721 samples, validate on 103 samples\n",
      "Epoch 1/100\n",
      "721/721 [==============================] - 0s 604us/sample - loss: 1399.2087 - mae: 33.4658 - val_loss: 1289.3557 - val_mae: 32.4450\n",
      "Epoch 2/100\n",
      "721/721 [==============================] - 0s 74us/sample - loss: 1137.3869 - mae: 29.6128 - val_loss: 988.3866 - val_mae: 27.7822\n",
      "Epoch 3/100\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 827.3642 - mae: 24.4455 - val_loss: 658.2984 - val_mae: 21.7277\n",
      "Epoch 4/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 526.5835 - mae: 18.5122 - val_loss: 401.4778 - val_mae: 16.0025\n",
      "Epoch 5/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 318.1560 - mae: 14.2674 - val_loss: 235.0124 - val_mae: 12.3810\n",
      "Epoch 6/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 225.8628 - mae: 12.1363 - val_loss: 200.1163 - val_mae: 11.3433\n",
      "Epoch 7/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 204.1576 - mae: 11.5716 - val_loss: 188.0912 - val_mae: 11.1894\n",
      "Epoch 8/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 191.8995 - mae: 11.2664 - val_loss: 179.9612 - val_mae: 11.1350\n",
      "Epoch 9/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 182.4866 - mae: 10.9896 - val_loss: 170.5943 - val_mae: 10.7931\n",
      "Epoch 10/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 173.9579 - mae: 10.7143 - val_loss: 165.6782 - val_mae: 10.5835\n",
      "Epoch 11/100\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 167.2958 - mae: 10.5424 - val_loss: 161.5638 - val_mae: 10.3894\n",
      "Epoch 12/100\n",
      "721/721 [==============================] - 0s 65us/sample - loss: 160.4026 - mae: 10.3337 - val_loss: 157.5767 - val_mae: 10.3247\n",
      "Epoch 13/100\n",
      "721/721 [==============================] - 0s 64us/sample - loss: 155.4994 - mae: 10.1690 - val_loss: 155.6329 - val_mae: 10.1584\n",
      "Epoch 14/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 151.4417 - mae: 9.9759 - val_loss: 153.1736 - val_mae: 10.1686\n",
      "Epoch 15/100\n",
      "721/721 [==============================] - 0s 63us/sample - loss: 147.1314 - mae: 9.8459 - val_loss: 151.9500 - val_mae: 10.1925\n",
      "Epoch 16/100\n",
      "721/721 [==============================] - 0s 64us/sample - loss: 144.2977 - mae: 9.7575 - val_loss: 151.6912 - val_mae: 10.1819\n",
      "Epoch 17/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 141.8760 - mae: 9.6877 - val_loss: 151.2015 - val_mae: 10.0006\n",
      "Epoch 18/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 139.1618 - mae: 9.5379 - val_loss: 150.1050 - val_mae: 10.0766\n",
      "Epoch 19/100\n",
      "721/721 [==============================] - 0s 73us/sample - loss: 136.7085 - mae: 9.4896 - val_loss: 149.0606 - val_mae: 9.8531\n",
      "Epoch 20/100\n",
      "721/721 [==============================] - 0s 71us/sample - loss: 134.1753 - mae: 9.3304 - val_loss: 149.5635 - val_mae: 10.1236\n",
      "Epoch 21/100\n",
      "721/721 [==============================] - 0s 76us/sample - loss: 131.7916 - mae: 9.3421 - val_loss: 145.1266 - val_mae: 9.8478\n",
      "Epoch 22/100\n",
      "721/721 [==============================] - 0s 67us/sample - loss: 130.2291 - mae: 9.2055 - val_loss: 143.6246 - val_mae: 9.8740\n",
      "Epoch 23/100\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 127.9130 - mae: 9.1525 - val_loss: 145.0364 - val_mae: 9.9272\n",
      "Epoch 24/100\n",
      "721/721 [==============================] - 0s 62us/sample - loss: 126.3049 - mae: 9.1034 - val_loss: 142.1088 - val_mae: 9.7274\n",
      "Epoch 25/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 124.7047 - mae: 8.9968 - val_loss: 139.8815 - val_mae: 9.6502\n",
      "Epoch 26/100\n",
      "721/721 [==============================] - 0s 69us/sample - loss: 123.5206 - mae: 8.9765 - val_loss: 139.6876 - val_mae: 9.6743\n",
      "Epoch 27/100\n",
      "721/721 [==============================] - 0s 68us/sample - loss: 121.0999 - mae: 8.9077 - val_loss: 138.2041 - val_mae: 9.5190\n",
      "Epoch 28/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 119.6284 - mae: 8.8008 - val_loss: 135.9803 - val_mae: 9.4570\n",
      "Epoch 29/100\n",
      "721/721 [==============================] - 0s 68us/sample - loss: 118.0295 - mae: 8.7422 - val_loss: 135.6933 - val_mae: 9.4536\n",
      "Epoch 30/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 116.7866 - mae: 8.7016 - val_loss: 134.9506 - val_mae: 9.4505\n",
      "Epoch 31/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 114.8921 - mae: 8.6685 - val_loss: 133.4177 - val_mae: 9.2797\n",
      "Epoch 32/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 113.1410 - mae: 8.5106 - val_loss: 131.5998 - val_mae: 9.2794\n",
      "Epoch 33/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 110.8582 - mae: 8.4321 - val_loss: 132.9027 - val_mae: 9.4385\n",
      "Epoch 34/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 108.7767 - mae: 8.4031 - val_loss: 130.6530 - val_mae: 9.1632\n",
      "Epoch 35/100\n",
      "721/721 [==============================] - 0s 72us/sample - loss: 108.4018 - mae: 8.3228 - val_loss: 128.7243 - val_mae: 9.2205\n",
      "Epoch 36/100\n",
      "721/721 [==============================] - 0s 71us/sample - loss: 106.0040 - mae: 8.2572 - val_loss: 127.7573 - val_mae: 9.0185\n",
      "Epoch 37/100\n",
      "721/721 [==============================] - 0s 72us/sample - loss: 104.6051 - mae: 8.1503 - val_loss: 128.2323 - val_mae: 9.0017\n",
      "Epoch 38/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 103.0453 - mae: 8.0704 - val_loss: 124.8282 - val_mae: 8.9477\n",
      "Epoch 39/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 101.5311 - mae: 8.0410 - val_loss: 123.1311 - val_mae: 8.8457\n",
      "Epoch 40/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 99.7309 - mae: 7.9117 - val_loss: 121.4284 - val_mae: 8.9159\n",
      "Epoch 41/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 99.0790 - mae: 7.9353 - val_loss: 121.1691 - val_mae: 8.9099\n",
      "Epoch 42/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 97.4321 - mae: 7.8847 - val_loss: 120.9780 - val_mae: 8.6444\n",
      "Epoch 43/100\n",
      "721/721 [==============================] - 0s 62us/sample - loss: 95.9475 - mae: 7.7447 - val_loss: 119.0546 - val_mae: 8.8219\n",
      "Epoch 44/100\n",
      "721/721 [==============================] - 0s 65us/sample - loss: 94.6061 - mae: 7.7400 - val_loss: 117.7441 - val_mae: 8.7578\n",
      "Epoch 45/100\n",
      "721/721 [==============================] - 0s 79us/sample - loss: 92.6949 - mae: 7.6912 - val_loss: 115.8829 - val_mae: 8.4351\n",
      "Epoch 46/100\n",
      "721/721 [==============================] - 0s 71us/sample - loss: 91.8457 - mae: 7.6061 - val_loss: 111.9891 - val_mae: 8.4394\n",
      "Epoch 47/100\n",
      "721/721 [==============================] - 0s 71us/sample - loss: 90.3912 - mae: 7.5362 - val_loss: 110.6041 - val_mae: 8.3690\n",
      "Epoch 48/100\n",
      "721/721 [==============================] - 0s 62us/sample - loss: 89.1670 - mae: 7.4629 - val_loss: 110.7175 - val_mae: 8.3900\n",
      "Epoch 49/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 87.5248 - mae: 7.3624 - val_loss: 109.8732 - val_mae: 8.1825\n",
      "Epoch 50/100\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 86.2150 - mae: 7.3306 - val_loss: 109.2733 - val_mae: 8.2031\n",
      "Epoch 51/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 85.3530 - mae: 7.2957 - val_loss: 108.7575 - val_mae: 8.0544\n",
      "Epoch 52/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 84.1380 - mae: 7.2109 - val_loss: 106.0293 - val_mae: 8.2454\n",
      "Epoch 53/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 82.8495 - mae: 7.1689 - val_loss: 105.4439 - val_mae: 8.2384\n",
      "Epoch 54/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 81.3892 - mae: 7.1125 - val_loss: 102.0354 - val_mae: 8.0253\n",
      "Epoch 55/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 80.2882 - mae: 7.0830 - val_loss: 103.4022 - val_mae: 7.8863\n",
      "Epoch 56/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 80.2379 - mae: 7.0196 - val_loss: 99.0732 - val_mae: 7.8367\n",
      "Epoch 57/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 78.0250 - mae: 6.9264 - val_loss: 99.6547 - val_mae: 7.6991\n",
      "Epoch 58/100\n",
      "721/721 [==============================] - 0s 66us/sample - loss: 76.5214 - mae: 6.8491 - val_loss: 97.2112 - val_mae: 7.6972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "721/721 [==============================] - 0s 68us/sample - loss: 75.3166 - mae: 6.8191 - val_loss: 96.1422 - val_mae: 7.7891\n",
      "Epoch 60/100\n",
      "721/721 [==============================] - 0s 72us/sample - loss: 74.1744 - mae: 6.7366 - val_loss: 93.3741 - val_mae: 7.5809\n",
      "Epoch 61/100\n",
      "721/721 [==============================] - 0s 63us/sample - loss: 72.7605 - mae: 6.6738 - val_loss: 95.8844 - val_mae: 7.5082\n",
      "Epoch 62/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 71.4333 - mae: 6.6122 - val_loss: 91.7592 - val_mae: 7.4620\n",
      "Epoch 63/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 69.4105 - mae: 6.4851 - val_loss: 91.4062 - val_mae: 7.5087\n",
      "Epoch 64/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 68.6120 - mae: 6.4519 - val_loss: 90.8483 - val_mae: 7.5124\n",
      "Epoch 65/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 67.8135 - mae: 6.4018 - val_loss: 90.6205 - val_mae: 7.3582\n",
      "Epoch 66/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 66.9610 - mae: 6.3210 - val_loss: 85.4294 - val_mae: 7.2374\n",
      "Epoch 67/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 66.0180 - mae: 6.3274 - val_loss: 85.0714 - val_mae: 7.2070\n",
      "Epoch 68/100\n",
      "721/721 [==============================] - 0s 73us/sample - loss: 64.2720 - mae: 6.2328 - val_loss: 83.3287 - val_mae: 7.0499\n",
      "Epoch 69/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 63.0388 - mae: 6.1402 - val_loss: 88.0413 - val_mae: 7.2002\n",
      "Epoch 70/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 62.5857 - mae: 6.1129 - val_loss: 84.6392 - val_mae: 7.2207\n",
      "Epoch 71/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 61.4078 - mae: 6.0654 - val_loss: 82.6310 - val_mae: 7.0755\n",
      "Epoch 72/100\n",
      "721/721 [==============================] - 0s 64us/sample - loss: 60.6423 - mae: 6.0122 - val_loss: 78.6935 - val_mae: 6.8279\n",
      "Epoch 73/100\n",
      "721/721 [==============================] - 0s 69us/sample - loss: 58.8046 - mae: 5.8957 - val_loss: 79.3560 - val_mae: 6.9036\n",
      "Epoch 74/100\n",
      "721/721 [==============================] - 0s 69us/sample - loss: 57.9422 - mae: 5.8661 - val_loss: 76.7246 - val_mae: 6.7712\n",
      "Epoch 75/100\n",
      "721/721 [==============================] - 0s 66us/sample - loss: 56.4575 - mae: 5.7654 - val_loss: 77.4902 - val_mae: 6.7878\n",
      "Epoch 76/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 56.5258 - mae: 5.7846 - val_loss: 74.7676 - val_mae: 6.6741\n",
      "Epoch 77/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 54.9132 - mae: 5.7037 - val_loss: 75.0229 - val_mae: 6.6894\n",
      "Epoch 78/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 53.5494 - mae: 5.6163 - val_loss: 78.9854 - val_mae: 6.8844\n",
      "Epoch 79/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 53.0819 - mae: 5.6177 - val_loss: 72.7949 - val_mae: 6.5001\n",
      "Epoch 80/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 52.1567 - mae: 5.5459 - val_loss: 76.8350 - val_mae: 6.7681\n",
      "Epoch 81/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 51.7630 - mae: 5.4943 - val_loss: 70.1371 - val_mae: 6.4319\n",
      "Epoch 82/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 49.8976 - mae: 5.4215 - val_loss: 70.6323 - val_mae: 6.3225\n",
      "Epoch 83/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 49.8387 - mae: 5.3936 - val_loss: 70.5704 - val_mae: 6.4252\n",
      "Epoch 84/100\n",
      "721/721 [==============================] - 0s 65us/sample - loss: 48.9134 - mae: 5.3334 - val_loss: 70.6917 - val_mae: 6.4792\n",
      "Epoch 85/100\n",
      "721/721 [==============================] - 0s 62us/sample - loss: 47.6641 - mae: 5.2593 - val_loss: 69.6904 - val_mae: 6.5041\n",
      "Epoch 86/100\n",
      "721/721 [==============================] - 0s 61us/sample - loss: 47.4752 - mae: 5.2640 - val_loss: 66.2806 - val_mae: 6.1702\n",
      "Epoch 87/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 46.3523 - mae: 5.1811 - val_loss: 66.3415 - val_mae: 6.1042\n",
      "Epoch 88/100\n",
      "721/721 [==============================] - 0s 67us/sample - loss: 45.9778 - mae: 5.1659 - val_loss: 65.0156 - val_mae: 6.1278\n",
      "Epoch 89/100\n",
      "721/721 [==============================] - 0s 70us/sample - loss: 45.3932 - mae: 5.1147 - val_loss: 66.3783 - val_mae: 6.0470\n",
      "Epoch 90/100\n",
      "721/721 [==============================] - 0s 73us/sample - loss: 45.0754 - mae: 5.1180 - val_loss: 66.6001 - val_mae: 6.3562\n",
      "Epoch 91/100\n",
      "721/721 [==============================] - 0s 79us/sample - loss: 44.2177 - mae: 5.0694 - val_loss: 63.3581 - val_mae: 6.0239\n",
      "Epoch 92/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 43.7320 - mae: 4.9955 - val_loss: 66.4979 - val_mae: 6.0056\n",
      "Epoch 93/100\n",
      "721/721 [==============================] - 0s 56us/sample - loss: 43.4138 - mae: 4.9636 - val_loss: 66.1419 - val_mae: 6.2677\n",
      "Epoch 94/100\n",
      "721/721 [==============================] - 0s 54us/sample - loss: 42.8783 - mae: 4.9660 - val_loss: 64.2126 - val_mae: 5.9815\n",
      "Epoch 95/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 42.1238 - mae: 4.8940 - val_loss: 65.1077 - val_mae: 6.0945\n",
      "Epoch 96/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 40.8878 - mae: 4.8456 - val_loss: 62.8767 - val_mae: 5.8566\n",
      "Epoch 97/100\n",
      "721/721 [==============================] - 0s 57us/sample - loss: 41.1304 - mae: 4.8700 - val_loss: 64.0364 - val_mae: 5.9580\n",
      "Epoch 98/100\n",
      "721/721 [==============================] - 0s 58us/sample - loss: 40.6076 - mae: 4.7800 - val_loss: 62.4653 - val_mae: 5.8525\n",
      "Epoch 99/100\n",
      "721/721 [==============================] - 0s 60us/sample - loss: 40.1993 - mae: 4.7977 - val_loss: 66.9328 - val_mae: 6.3372\n",
      "Epoch 100/100\n",
      "721/721 [==============================] - 0s 59us/sample - loss: 39.5556 - mae: 4.7637 - val_loss: 60.1925 - val_mae: 5.6354\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(partial_x_train,partial_train_label,epochs=100,batch_size=30,validation_data=(x_val,val_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mse, val_mae = model.evaluate(x_val, val_label, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "206/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0s/sample - loss: 38.9776 - mae: 4.2765\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, train_labels,\n",
    "          epochs=80, batch_size=16, verbose=0)\n",
    "test_mse_score, test_mae_score = model.evaluate(y_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2765274"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_mae_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
